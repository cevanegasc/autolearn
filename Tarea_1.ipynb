{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TAREA 1: TUTORIAL SOBRE USO DE PANDAS PARA EL PREPROCESADO DE DATOS EN APRENDIZAJE SUPERVISADO DE DATOS**\n",
        "\n",
        "*INTRODUCCIÓN*\n",
        "\n",
        "Los paradigmas de las metodologías de Machine Learning o Aprendizaje Automático revolucionaron el entorno del análisis de datos, ya que antes de ser modelos descriptivos, su arquitectura compuesta por, generalmente, un robusto set de datos, conlleva procesos de aprendizaje para lo cual utiliza. una buena porción de dichos datos, con el fin de establecer los patrones o modelos que permitan establecer generalizaciones asociadas a las clases.\n",
        "\n",
        "En la práctica el Aprendizaje Automático implica llevar a cabo un proceso de entrenamiento de un sistema mediante la insersión de datos masivos (set de datos o dataset), considerados ejemplos, **instancias u observaciones**, en los cuales se pueden identificar los encabezados de las columnas como **atributos** o **características**, considerando el último vector columna como el vector de clases o sencillamente **clases o tipos**\n",
        "\n",
        "A continuación se listan las tareas del proceso que un sistema de Aprendizaje Automático debellevar a cabo:\n",
        "\n",
        "1.   **Preprocesado del set de datos o dataset**: Para el entorno de este tutorial, se exige que los datos cuenten con etiquetas, ya que se trata de aprendizaje supervisado. El preprocesado consiste el el conjunto de tareas realizadas por el científico para garantizar la calidad e integridad de los datos antes de aplicar los algoritmos de aprendizaje automático, y este proceso podría incluir las siguientes tareas:\n",
        "* **Eliminar**: Con el fin de prevenir resultados cesgados (Outliers) por datos atípicos, se requiere que el científico de datos identifique y elimine este tipo de datos del dataset.\n",
        "* **Resolver la nulidad de datos**: Es posible que algunas de las entradas del dataset aparezcan vacías, en cuyo caso el científico de datos debe dar una solución manejable a este tipo de problema.\n",
        "* **Transformar (normalizar / estandarizar)**: Algunos datos podrían estar en una escala inadecuada o podrían estar vacíos, o eventualmente tener un aspecto ilegible o que impida realizar algún tipo de operació matemática para su tratamiento, y en estos casos el científico de datos debe transformar los datos al formato y unidades adecuadas para el procesamiento.\n",
        "* **Generar**: En caso de que el dataset no ofrezca suficiente información para la generalización, será indispensable que el científico de datos genere a través de alguna metodología instancias adicionales que enriquezcan el dataset.\n",
        "Datos de o en el dataset a fin de que el modelo comience bajo condiciones adecuadas\n",
        "\n",
        "2. **Aprendizaje**: Se inyectan las instancias al sistema con el propósito de crear el modelo que será evaluado en la siguiente etapa.\n",
        "3. **Evaluación del Modelo**: En la evaluación se considera la porción complementaria de instancias del dataset que no fue utilizada en la fase anterior a fin de que el sistema pueda ser probado y así determinar que es correcto o si es necesario hacer ajustes.\n",
        "4. **Predicción**: En esta fase se consolidan las etiquetas de resultado.\n",
        "\n",
        "\n",
        "*FASES PROPIAS DEL PREPROCESADO DE DATOS APLICADAS A UN EJEMPLO PUNTUAL*\n",
        "\n",
        "Dentro de las herramientas típicas de trabajo en ciencia de Datos encontramos PANDAS, se trata de una biblioteca escrita para el lenguaje Python, que incluye herramientas y funciones para la manipulación y análisis de datos; fue creada por Wes McKinney en 2008 con el propósito de contar con una herramienta para el manejo de datos financieros, sin embargo la librería ha alcanzado un papel preponderante en el ámbito del Aprendizaje Supervisado por su flexibilidad en la transformación de conjuntos masivos de datos.\n",
        "\n",
        "Dado que el foco de este tutorial se centra en las herramientas o librerías utilizadas para el procesamiento de datos, se realiza una descripción de las principales funciones de la librería PANDAS en las tareas de preprocesado de datos.\n",
        "\n",
        "**Nota**: para hacer uso de la librería PANDAS es necesario importarla al entorno de programación, y usualmente se asigna un alias para invocar o llamar a la librería o a alguna de sus funciones, esto se logra mediante la siguiente instrucción:\n",
        "\n"
      ],
      "metadata": {
        "id": "k_bscHP1X83p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hMlhgX-Y9jbU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El alias pd facilitará la llamada de la librería dentro de cualquier bloque de código del libro a partir de la línea en la que se ha ejecutado la importación"
      ],
      "metadata": {
        "id": "RRQrVlqy9wdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importación o carga de datos desde un CSV: En este caso utlizaremos un set de datos que puede ser accedido desde el siguiente enlace:\n",
        "\n",
        "https://www.kaggle.com/datasets/PromptCloudHQ/world-happiness-report-2019?resource=download\n",
        "\n",
        "Nota: Para el ejemplo hemos llamado el archivo felicidad.csv\n",
        "\n",
        "Esta tarea se logra mediante la siguiente línea de comando: 1"
      ],
      "metadata": {
        "id": "XLM9pEFf-ZXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('felicidad.csv')"
      ],
      "metadata": {
        "id": "BKJa79Ez-mb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}